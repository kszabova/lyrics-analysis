{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing the Quality of the tf_idf() Metric\n",
    "\n",
    "In this notebook, we will use the pre-generated\n",
    "evaluation sets to test the quality of the `tf_idf()`\n",
    "metric.\n",
    "\n",
    "The `tf_idf()` metric computes the average tfidf\n",
    "score over all words in the lyrics. The tfidf\n",
    "score of a word stands for *term frequency -\n",
    "inverse document frequency* and determines how\n",
    "important a word is in the context of a single\n",
    "document and the whole corpus.\n",
    "\n",
    "We use the entire song dataset as the corpus\n",
    "from which the scores are computed. We used\n",
    "the `gensim` library to create a TfidfModel\n",
    "and stored it so as not to need to generate\n",
    "it again every time it is needed.\n",
    "\n",
    "The evaluation test sets were generated using\n",
    "the `_generate_metric_quality_sets()` method\n",
    "from the `helpers` submodule. We will use 3 sets\n",
    "of unmodified lyrics, and for each probability\n",
    "in {0.1, 0.5, 0.8} three sets of lyrics with\n",
    "randomly removed words anywhere on the line\n",
    "and three sets of lyrics with randomly removed\n",
    "words at the end of line. Each test set contains\n",
    "1000 songs.\n",
    "\n",
    "To determine the quality of the metric, we will\n",
    "compute the average score of each test set\n",
    "and compare the relation to the expected relation.\n",
    "For further explanation see the notebook\n",
    "`05_test_rhyme_metric_quality.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kristina\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import functools\n",
    "import lyrics_analysis\n",
    "\n",
    "evaluation_sets = [\n",
    "    [\n",
    "        \"1000_removed_all_words0.8_1.json\",\n",
    "        \"1000_removed_all_words0.8_2.json\",\n",
    "        \"1000_removed_all_words0.8_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_last_words0.8_1.json\",\n",
    "        \"1000_removed_last_words0.8_2.json\",\n",
    "        \"1000_removed_last_words0.8_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_all_words0.5_1.json\",\n",
    "        \"1000_removed_all_words0.5_2.json\",\n",
    "        \"1000_removed_all_words0.5_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_last_words0.5_1.json\",\n",
    "        \"1000_removed_last_words0.5_2.json\",\n",
    "        \"1000_removed_last_words0.5_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_all_words0.1_1.json\",\n",
    "        \"1000_removed_all_words0.1_2.json\",\n",
    "        \"1000_removed_all_words0.1_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_last_words0.1_1.json\",\n",
    "        \"1000_removed_last_words0.1_2.json\",\n",
    "        \"1000_removed_last_words0.1_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_id0.1_1.json\",\n",
    "        \"1000_id0.1_2.json\",\n",
    "        \"1000_id0.1_3.json\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "directory = \"../data/metric_quality_tests/\"\n",
    "\n",
    "eval_generators = [\n",
    "    [\n",
    "        lyrics_analysis.helpers._get_generator_from_file(directory + file) for file in set\n",
    "    ]\n",
    "    for set in evaluation_sets\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we retrieve the saved dictionary and tfidf model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dict = gensim.corpora.Dictionary.load(\"../models/tfidf.dict\")\n",
    "model = gensim.models.TfidfModel.load(\"../models/tfidf.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To test the metric, we will use the `calculate_metric_quality()`\n",
    "method from the `tests` submodule."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10582010582010581\n"
     ]
    }
   ],
   "source": [
    "score = lyrics_analysis.tests.calculate_metric_quality(\n",
    "    functools.partial(lyrics_analysis.evaluation.tf_idf, dictionary=dict, tfidf=model),\n",
    "    eval_generators\n",
    ")\n",
    "\n",
    "print(score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the metric performance is very poor,\n",
    "but that might be because we defined the expected\n",
    "order wrong."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "eval_sets1 = [\n",
    "    [\n",
    "        \"1000_removed_last_words0.8_1.json\",\n",
    "        \"1000_removed_last_words0.8_2.json\",\n",
    "        \"1000_removed_last_words0.8_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_last_words0.5_1.json\",\n",
    "        \"1000_removed_last_words0.5_2.json\",\n",
    "        \"1000_removed_last_words0.5_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_last_words0.1_1.json\",\n",
    "        \"1000_removed_last_words0.1_2.json\",\n",
    "        \"1000_removed_last_words0.1_3.json\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "directory = \"../data/metric_quality_tests/\"\n",
    "\n",
    "eval_generators = [\n",
    "    [\n",
    "        lyrics_analysis.helpers._get_generator_from_file(directory + file) for file in set\n",
    "    ]\n",
    "    for set in eval_sets1\n",
    "]\n",
    "\n",
    "score = lyrics_analysis.tests.calculate_metric_quality(\n",
    "    functools.partial(lyrics_analysis.evaluation.tf_idf, dictionary=dict, tfidf=model),\n",
    "    eval_generators\n",
    ")\n",
    "\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "eval_sets2 = [\n",
    "    [\n",
    "        \"1000_removed_all_words0.8_1.json\",\n",
    "        \"1000_removed_all_words0.8_2.json\",\n",
    "        \"1000_removed_all_words0.8_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_all_words0.5_1.json\",\n",
    "        \"1000_removed_all_words0.5_2.json\",\n",
    "        \"1000_removed_all_words0.5_3.json\"\n",
    "    ],\n",
    "    [\n",
    "        \"1000_removed_all_words0.1_1.json\",\n",
    "        \"1000_removed_all_words0.1_2.json\",\n",
    "        \"1000_removed_all_words0.1_3.json\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "directory = \"../data/metric_quality_tests/\"\n",
    "\n",
    "eval_generators = [\n",
    "    [\n",
    "        lyrics_analysis.helpers._get_generator_from_file(directory + file) for file in set\n",
    "    ]\n",
    "    for set in eval_sets2\n",
    "]\n",
    "\n",
    "score = lyrics_analysis.tests.calculate_metric_quality(\n",
    "    functools.partial(lyrics_analysis.evaluation.tf_idf, dictionary=dict, tfidf=model),\n",
    "    eval_generators\n",
    ")\n",
    "\n",
    "print(score)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}